{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c0f331-3745-403c-8e2f-afcf12160918",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:3.1.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6500180d-3af7-493b-a5c5-74f9eeec7e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/26 18:52:49 INFO BlockManagerInfo: Removed broadcast_2_piece0 on andersons-mbp:54253 in memory (size: 5.7 KiB, free: 4.6 GiB)\n",
      "21/07/26 18:52:49 INFO BlockManagerInfo: Removed broadcast_3_piece0 on andersons-mbp:54253 in memory (size: 5.7 KiB, free: 4.6 GiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.SparkSession\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.{Row}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.{Row}\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c08477c-3d60-49df-840b-3f8f213358e2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/26 18:48:33 WARN SparkSession$Builder: Using an existing SparkSession; some spark core configurations may not take effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@301fffbb"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession\n",
    "    .builder()\n",
    "    .appName(\"Spark SQL basic example\")\n",
    "    .master(\"local\")\n",
    "    .config(\"spark.executor.instances\", \"4\")\n",
    "    .config(\"spark.executor.memory\", \"2g\")\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac87487d-8226-432e-9efc-907f2fc5cc2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mvoteRDD\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mrdd\u001b[39m.\u001b[32mRDD\u001b[39m[\u001b[32mRow\u001b[39m] = ParallelCollectionRDD[4] at parallelize at cmd10.sc:1\n",
       "\u001b[36mvoteSchema\u001b[39m: \u001b[32mStructType\u001b[39m = \u001b[33mStructType\u001b[39m(\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Name\"\u001b[39m, StringType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Age\"\u001b[39m, IntegerType, true, {}),\n",
       "  \u001b[33mStructField\u001b[39m(\u001b[32m\"Voted\"\u001b[39m, BooleanType, true, {})\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val voteRDD = spark.sparkContext.parallelize(List(\n",
    "    Row(\"Anderson\", 20, true),\n",
    "    Row(\"Fulano\", 34, false),\n",
    "    Row(\"Ciclano\", 17, true),\n",
    "    Row(\"Deltrano\", 67, false)\n",
    "))\n",
    "\n",
    "val voteSchema = StructType(List(\n",
    "    StructField(\"Name\", StringType, true),\n",
    "    StructField(\"Age\", IntegerType, true),\n",
    "    StructField(\"Voted\", BooleanType, true)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65409908-c21e-400e-aa36-121e4b0148ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/26 18:58:54 INFO BlockManagerInfo: Removed broadcast_20_piece0 on andersons-mbp:54253 in memory (size: 15.1 KiB, free: 4.6 GiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mvote_df\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32msql\u001b[39m.\u001b[32mpackage\u001b[39m.\u001b[32mDataFrame\u001b[39m = [Name: string, Age: int ... 1 more field]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vote_df = spark.createDataFrame(voteRDD, voteSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd3be17d-0d32-44d3-93ce-cfa9e3394545",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/26 18:48:36 INFO SparkContext: Starting job: show at cmd12.sc:1\n",
      "21/07/26 18:48:36 INFO DAGScheduler: Got job 1 (show at cmd12.sc:1) with 1 output partitions\n",
      "21/07/26 18:48:36 INFO DAGScheduler: Final stage: ResultStage 1 (show at cmd12.sc:1)\n",
      "21/07/26 18:48:36 INFO DAGScheduler: Parents of final stage: List()\n",
      "21/07/26 18:48:36 INFO DAGScheduler: Missing parents: List()\n",
      "21/07/26 18:48:36 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at show at cmd12.sc:1), which has no missing parents\n",
      "21/07/26 18:48:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.8 KiB, free 4.6 GiB)\n",
      "21/07/26 18:48:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 4.6 GiB)\n",
      "21/07/26 18:48:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on andersons-mbp:54253 (size: 5.5 KiB, free: 4.6 GiB)\n",
      "21/07/26 18:48:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1388\n",
      "21/07/26 18:48:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at show at cmd12.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "21/07/26 18:48:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0\n",
      "21/07/26 18:48:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (andersons-mbp, executor driver, partition 0, PROCESS_LOCAL, 4797 bytes) taskResourceAssignments Map()\n",
      "21/07/26 18:48:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)\n",
      "21/07/26 18:48:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1486 bytes result sent to driver\n",
      "21/07/26 18:48:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 16 ms on andersons-mbp (executor driver) (1/1)\n",
      "21/07/26 18:48:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "21/07/26 18:48:36 INFO DAGScheduler: ResultStage 1 (show at cmd12.sc:1) finished in 0.034 s\n",
      "21/07/26 18:48:36 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "21/07/26 18:48:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished\n",
      "21/07/26 18:48:36 INFO DAGScheduler: Job 1 finished: show at cmd12.sc:1, took 0.037472 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+-----+\n",
      "|    Name|Age|Voted|\n",
      "+--------+---+-----+\n",
      "|Anderson| 20| true|\n",
      "|  Fulano| 34|false|\n",
      "| Ciclano| 17| true|\n",
      "|Deltrano| 67|false|\n",
      "+--------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vote_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "158512a3-27c6-45ed-9275-d091ad6cd502",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/26 18:55:18 INFO SparkContext: Starting job: show at cmd21.sc:1\n",
      "21/07/26 18:55:18 INFO DAGScheduler: Got job 8 (show at cmd21.sc:1) with 1 output partitions\n",
      "21/07/26 18:55:18 INFO DAGScheduler: Final stage: ResultStage 8 (show at cmd21.sc:1)\n",
      "21/07/26 18:55:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "21/07/26 18:55:18 INFO DAGScheduler: Missing parents: List()\n",
      "21/07/26 18:55:18 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[21] at show at cmd21.sc:1), which has no missing parents\n",
      "21/07/26 18:55:18 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 13.5 KiB, free 4.6 GiB)\n",
      "21/07/26 18:55:18 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 4.6 GiB)\n",
      "21/07/26 18:55:18 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on andersons-mbp:54253 (size: 5.8 KiB, free: 4.6 GiB)\n",
      "21/07/26 18:55:18 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1388\n",
      "21/07/26 18:55:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[21] at show at cmd21.sc:1) (first 15 tasks are for partitions Vector(0))\n",
      "21/07/26 18:55:18 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0\n",
      "21/07/26 18:55:18 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8) (andersons-mbp, executor driver, partition 0, PROCESS_LOCAL, 4797 bytes) taskResourceAssignments Map()\n",
      "21/07/26 18:55:18 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)\n",
      "21/07/26 18:55:18 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 1467 bytes result sent to driver\n",
      "21/07/26 18:55:18 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 9 ms on andersons-mbp (executor driver) (1/1)\n",
      "21/07/26 18:55:18 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool \n",
      "21/07/26 18:55:18 INFO DAGScheduler: ResultStage 8 (show at cmd21.sc:1) finished in 0.016 s\n",
      "21/07/26 18:55:18 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "21/07/26 18:55:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished\n",
      "21/07/26 18:55:18 INFO DAGScheduler: Job 8 finished: show at cmd21.sc:1, took 0.018252 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-----+\n",
      "|   Name|Age|Voted|\n",
      "+-------+---+-----+\n",
      "|Ciclano| 17| true|\n",
      "+-------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vote_df\n",
    "    .filter($\"Voted\" && $\"Name\" =!= \"Anderson\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c57b7d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) HashAggregate(keys=[Voted#27], functions=[sum(cast(Age#26 as bigint))])\n",
      "+- Exchange hashpartitioning(Voted#27, 200), ENSURE_REQUIREMENTS, [id=#263]\n",
      "   +- *(1) HashAggregate(keys=[Voted#27], functions=[partial_sum(cast(Age#26 as bigint))])\n",
      "      +- *(1) Project [Age#26, Voted#27]\n",
      "         +- *(1) Scan ExistingRDD[Name#25,Age#26,Voted#27]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vote_df\n",
    "    .groupBy($\"Voted\")\n",
    "    .agg(sum($\"Age\").alias(\"AgeAvg\"))\n",
    "    .explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e934b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
